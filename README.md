# Maximum Likelihood Estimation (MLE) for Parameter Estimation

## Introduction

This repository explores Maximum Likelihood Estimation (MLE) applied to parameter estimation for two fundamental probability distributions:

- **Binomial Distribution**: Models the number of successes in a fixed number of independent Bernoulli trials.
  - Example: Coin tosses, where each toss has a binary outcome (heads or tails).

- **Normal Distribution**: Describes continuous random variables with a symmetric bell-shaped curve.
  - Example: Heights of a population, where most individuals cluster around the mean height.

## Parameter Estimation

Parameter estimation involves determining the unknown parameters of a statistical model based on observed data.

- **Binomial Distribution Parameters**: Success probability (p) and number of trials (n).
  - Example: Estimating the probability of a coin landing heads up after flipping it 100 times.

- **Normal Distribution Parameters**: Mean (μ) and standard deviation (σ).
  - Example: Estimating the average height and variability in a population sample.

## Maximum Likelihood Estimation (MLE)

MLE is a method for estimating the parameters of a statistical model by maximizing the likelihood function.

- **Binomial Distribution MLE**: Estimate p-hat by maximizing the likelihood of observing the data given p.
  - Example: Finding the value of p-hat that maximizes the likelihood of getting 70 heads in 100 coin flips.

- **Normal Distribution MLE**: Estimate μ-hat and σ-hat by maximizing the likelihood of the observed data.
  - Example: Finding the values of μ-hat and σ-hat that maximize the likelihood of the sample heights.

## Conclusion

This repository provides insights into MLE as a powerful tool for parameter estimation in statistical modeling, with practical examples from binomial and normal distributions.

---

Explore the world of Maximum Likelihood Estimation and enhance your understanding of parameter estimation in probability distributions!
